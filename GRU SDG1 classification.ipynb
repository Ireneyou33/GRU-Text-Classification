{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('volunteer_world_SDG1.csv', encoding='utf-8')\n",
    "df2 = pd.read_csv('volunteer_world_SDG2.csv', encoding='utf-8')\n",
    "df = df.append(df2, ignore_index=True)\n",
    "des = df['Description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['res']=0\n",
    "df['res'][:15]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "res = df['res'].tolist()\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "des_lines=list()\n",
    "for line in des:\n",
    "    line = line.replace('\\\\n','')\n",
    "    line = line.replace('\\\\xa05','')\n",
    "    line = line.replace('\\\\xa0','')\n",
    "    tokens = word_tokenize(line)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    des_lines.append(words)\n",
    "print(len(des_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=100\n",
    "MIN_COUNT=4\n",
    "WINDOW=5 # the max distance btw a target word and words around it.\n",
    "WORKERS=3 #the num of partitions during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1021 20:48:57.699760  1140 base_any2vec.py:1386] under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:1316\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences=des_lines, size=EMBEDDING_DIM, \n",
    "                               window=WINDOW, min_count=MIN_COUNT, workers=WORKERS)\n",
    "words = list(model.wv.vocab)\n",
    "print('Vocab size:{}'.format(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('volunteers', 0.9998090863227844),\n",
       " ('project', 0.9997903108596802),\n",
       " ('local', 0.9997694492340088),\n",
       " ('work', 0.999762773513794),\n",
       " ('like', 0.9997480511665344),\n",
       " ('health', 0.999747633934021),\n",
       " ('one', 0.9997432231903076),\n",
       " ('help', 0.9997345209121704),\n",
       " ('families', 0.9997216463088989),\n",
       " ('activities', 0.9997215270996094)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('children')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SDG1_Word2Vec.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "embeddings_index={}\n",
    "f = open(os.path.join('', 'SDG1_Word2Vec.txt'), encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(des_lines)\n",
    "sequences = tokenizer_obj.texts_to_sequences(des_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6444 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# pad sequences\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('{} unique tokens.'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_pad = pad_sequences(sequences, maxlen=1000)\n",
    "des_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  352,   21,   67],\n",
       "       [   0,    0,    0, ...,  262,   92,  632],\n",
       "       [   0,    0,    0, ...,   87, 1816,    1],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  667,  442,   81],\n",
       "       [   0,    0,    0, ..., 6363, 6364, 6365],\n",
       "       [   0,    0,    0, ..., 1878,    2,  905]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(word_index)+1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6445\n"
     ]
    }
   ],
   "source": [
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(num_words, EMBEDDING_DIM, \n",
    "                            embeddings_initializer = Constant(embedding_matrix),\n",
    "                           trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         644500    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                12864     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 657,397\n",
      "Trainable params: 12,897\n",
      "Non-trainable params: 644,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "indices = np.arange(des_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "des_pad = des_pad[indices]\n",
    "res = np.array(res)\n",
    "res = res[indices.astype(int)]\n",
    "num_vali_samples = int(VALIDATION_SPLIT*des_pad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = des_pad[:-num_vali_samples]\n",
    "y_train = res[:-num_vali_samples]\n",
    "X_test_pad = des_pad[-num_vali_samples:]\n",
    "y_test = res[-num_vali_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad tensor: (48, 1000)\n",
      "Shape of y_train tensor: (48,)\n",
      "Shape of X_test_pad tensor: (12, 1000)\n",
      "Shape of y_test tensor: (12,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train_pad tensor: {}'.format(X_train_pad.shape))\n",
    "print('Shape of y_train tensor: {}'.format(y_train.shape))\n",
    "print('Shape of X_test_pad tensor: {}'.format(X_test_pad.shape))\n",
    "print('Shape of y_test tensor: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "24/24 - 9s - loss: 0.6556 - accuracy: 0.7292 - val_loss: 0.5582 - val_accuracy: 0.8333\n",
      "Epoch 2/15\n",
      "24/24 - 7s - loss: 0.6171 - accuracy: 0.7292 - val_loss: 0.5366 - val_accuracy: 0.8333\n",
      "Epoch 3/15\n",
      "24/24 - 9s - loss: 0.6139 - accuracy: 0.7292 - val_loss: 0.5377 - val_accuracy: 0.8333\n",
      "Epoch 4/15\n",
      "24/24 - 11s - loss: 0.6072 - accuracy: 0.7292 - val_loss: 0.5275 - val_accuracy: 0.8333\n",
      "Epoch 5/15\n",
      "24/24 - 7s - loss: 0.6001 - accuracy: 0.7292 - val_loss: 0.5122 - val_accuracy: 0.8333\n",
      "Epoch 6/15\n",
      "24/24 - 7s - loss: 0.6062 - accuracy: 0.7292 - val_loss: 0.5187 - val_accuracy: 0.8333\n",
      "Epoch 7/15\n",
      "24/24 - 12s - loss: 0.5954 - accuracy: 0.7292 - val_loss: 0.5114 - val_accuracy: 0.8333\n",
      "Epoch 8/15\n",
      "24/24 - 7s - loss: 0.6105 - accuracy: 0.7292 - val_loss: 0.5008 - val_accuracy: 0.8333\n",
      "Epoch 9/15\n",
      "24/24 - 7s - loss: 0.6101 - accuracy: 0.7292 - val_loss: 0.5257 - val_accuracy: 0.8333\n",
      "Epoch 10/15\n",
      "24/24 - 10s - loss: 0.5862 - accuracy: 0.7292 - val_loss: 0.5042 - val_accuracy: 0.8333\n",
      "Epoch 11/15\n",
      "24/24 - 9s - loss: 0.5948 - accuracy: 0.7292 - val_loss: 0.4953 - val_accuracy: 0.8333\n",
      "Epoch 12/15\n",
      "24/24 - 7s - loss: 0.5877 - accuracy: 0.7292 - val_loss: 0.4971 - val_accuracy: 0.8333\n",
      "Epoch 13/15\n",
      "24/24 - 9s - loss: 0.5922 - accuracy: 0.7292 - val_loss: 0.5016 - val_accuracy: 0.8333\n",
      "Epoch 14/15\n",
      "24/24 - 10s - loss: 0.5913 - accuracy: 0.7292 - val_loss: 0.4949 - val_accuracy: 0.8333\n",
      "Epoch 15/15\n",
      "24/24 - 7s - loss: 0.5945 - accuracy: 0.7292 - val_loss: 0.4882 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfcbfbd208>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, batch_size=2, epochs=15, \n",
    "          validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 - 4s - loss: 0.5737 - accuracy: 0.7292 - val_loss: 0.4742 - val_accuracy: 0.8333\n",
      "Epoch 2/30\n",
      "10/10 - 4s - loss: 0.5704 - accuracy: 0.7292 - val_loss: 0.4805 - val_accuracy: 0.8333\n",
      "Epoch 3/30\n",
      "10/10 - 4s - loss: 0.5710 - accuracy: 0.7292 - val_loss: 0.4800 - val_accuracy: 0.8333\n",
      "Epoch 4/30\n",
      "10/10 - 4s - loss: 0.5761 - accuracy: 0.7292 - val_loss: 0.4811 - val_accuracy: 0.8333\n",
      "Epoch 5/30\n",
      "10/10 - 6s - loss: 0.5616 - accuracy: 0.7292 - val_loss: 0.4812 - val_accuracy: 0.8333\n",
      "Epoch 6/30\n",
      "10/10 - 6s - loss: 0.5657 - accuracy: 0.7292 - val_loss: 0.4840 - val_accuracy: 0.8333\n",
      "Epoch 7/30\n",
      "10/10 - 7s - loss: 0.5621 - accuracy: 0.7292 - val_loss: 0.4810 - val_accuracy: 0.8333\n",
      "Epoch 8/30\n",
      "10/10 - 4s - loss: 0.5629 - accuracy: 0.7292 - val_loss: 0.4685 - val_accuracy: 0.8333\n",
      "Epoch 9/30\n",
      "10/10 - 4s - loss: 0.5595 - accuracy: 0.7292 - val_loss: 0.4770 - val_accuracy: 0.8333\n",
      "Epoch 10/30\n",
      "10/10 - 6s - loss: 0.5580 - accuracy: 0.7292 - val_loss: 0.4771 - val_accuracy: 0.8333\n",
      "Epoch 11/30\n",
      "10/10 - 6s - loss: 0.5570 - accuracy: 0.7292 - val_loss: 0.4780 - val_accuracy: 0.8333\n",
      "Epoch 12/30\n",
      "10/10 - 6s - loss: 0.5663 - accuracy: 0.7292 - val_loss: 0.4767 - val_accuracy: 0.8333\n",
      "Epoch 13/30\n",
      "10/10 - 4s - loss: 0.5608 - accuracy: 0.7292 - val_loss: 0.4845 - val_accuracy: 0.8333\n",
      "Epoch 14/30\n",
      "10/10 - 4s - loss: 0.5611 - accuracy: 0.7292 - val_loss: 0.4732 - val_accuracy: 0.8333\n",
      "Epoch 15/30\n",
      "10/10 - 5s - loss: 0.5508 - accuracy: 0.7292 - val_loss: 0.4763 - val_accuracy: 0.8333\n",
      "Epoch 16/30\n",
      "10/10 - 4s - loss: 0.5541 - accuracy: 0.7500 - val_loss: 0.4698 - val_accuracy: 0.8333\n",
      "Epoch 17/30\n",
      "10/10 - 4s - loss: 0.5514 - accuracy: 0.7292 - val_loss: 0.4634 - val_accuracy: 0.8333\n",
      "Epoch 18/30\n",
      "10/10 - 4s - loss: 0.5523 - accuracy: 0.7500 - val_loss: 0.4710 - val_accuracy: 0.8333\n",
      "Epoch 19/30\n",
      "10/10 - 4s - loss: 0.5520 - accuracy: 0.7500 - val_loss: 0.4741 - val_accuracy: 0.8333\n",
      "Epoch 20/30\n",
      "10/10 - 4s - loss: 0.5694 - accuracy: 0.7500 - val_loss: 0.4926 - val_accuracy: 0.8333\n",
      "Epoch 21/30\n",
      "10/10 - 4s - loss: 0.5498 - accuracy: 0.7708 - val_loss: 0.4771 - val_accuracy: 0.8333\n",
      "Epoch 22/30\n",
      "10/10 - 7s - loss: 0.5502 - accuracy: 0.7500 - val_loss: 0.4747 - val_accuracy: 0.8333\n",
      "Epoch 23/30\n",
      "10/10 - 6s - loss: 0.5444 - accuracy: 0.7292 - val_loss: 0.4647 - val_accuracy: 0.8333\n",
      "Epoch 24/30\n",
      "10/10 - 4s - loss: 0.5398 - accuracy: 0.7500 - val_loss: 0.4718 - val_accuracy: 0.8333\n",
      "Epoch 25/30\n",
      "10/10 - 8s - loss: 0.5359 - accuracy: 0.7708 - val_loss: 0.4764 - val_accuracy: 0.8333\n",
      "Epoch 26/30\n",
      "10/10 - 7s - loss: 0.5379 - accuracy: 0.7708 - val_loss: 0.4739 - val_accuracy: 0.8333\n",
      "Epoch 27/30\n",
      "10/10 - 10s - loss: 0.5454 - accuracy: 0.7500 - val_loss: 0.4688 - val_accuracy: 0.8333\n",
      "Epoch 28/30\n",
      "10/10 - 6s - loss: 0.5463 - accuracy: 0.7292 - val_loss: 0.4761 - val_accuracy: 0.8333\n",
      "Epoch 29/30\n",
      "10/10 - 6s - loss: 0.5353 - accuracy: 0.7708 - val_loss: 0.4787 - val_accuracy: 0.8333\n",
      "Epoch 30/30\n",
      "10/10 - 6s - loss: 0.5246 - accuracy: 0.7917 - val_loss: 0.4737 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfda5c9a58>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, batch_size=5, epochs=30, \n",
    "          validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
